name: databricks-shared-utilities CI

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'databricks-shared-utilities/**'
      - 'spark-session-utilities/**'
      - 'databricks-uc-utilities/**'
      - '.github/workflows/databricks-shared-utilities-ci.yml'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'databricks-shared-utilities/**'
      - 'spark-session-utilities/**'
      - 'databricks-uc-utilities/**'
      - '.github/workflows/databricks-shared-utilities-ci.yml'

jobs:
  # Wait for dependencies to build first
  wait-for-dependencies:
    name: Wait for dependency packages
    runs-on: ubuntu-latest
    steps:
    - name: Check if running after dependency builds
      run: echo "Dependency packages should be built before this"

  test:
    name: Test Python ${{ matrix.python-version }}
    runs-on: ubuntu-latest
    needs: wait-for-dependencies
    strategy:
      matrix:
        python-version: ['3.10', '3.11']

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install Java (required for PySpark via spark-session-utilities)
      uses: actions/setup-java@v3
      with:
        distribution: 'temurin'
        java-version: '11'

    - name: Cache pip packages
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-shared-${{ hashFiles('databricks-shared-utilities/pyproject.toml') }}
        restore-keys: |
          ${{ runner.os }}-pip-shared-

    - name: Install spark-session-utilities
      working-directory: spark-session-utilities
      run: |
        python -m pip install --upgrade pip
        pip install -e .

    - name: Install databricks-uc-utilities
      working-directory: databricks-uc-utilities
      run: |
        pip install -e .

    - name: Install databricks-shared-utilities
      working-directory: databricks-shared-utilities
      run: |
        pip install -e ".[dev]"

    - name: Verify version pinning
      working-directory: databricks-shared-utilities
      run: |
        # Check that exact versions are installed
        pip list | grep spark-session-utilities
        pip list | grep databricks-uc-utilities

    - name: Lint with ruff
      working-directory: databricks-shared-utilities
      run: |
        ruff check src tests

    - name: Check formatting with black
      working-directory: databricks-shared-utilities
      run: |
        black --check src tests

    - name: Type check with mypy
      working-directory: databricks-shared-utilities
      run: |
        mypy src
      continue-on-error: true

    - name: Run unit tests
      working-directory: databricks-shared-utilities
      run: |
        pytest tests/unit -v --cov=databricks_utils --cov-report=xml --cov-report=term-missing

    - name: Run integration tests
      working-directory: databricks-shared-utilities
      run: |
        pytest tests/integration -v
      continue-on-error: true

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: databricks-shared-utilities/coverage.xml
        flags: databricks-shared-utilities
        name: databricks-shared-utilities-${{ matrix.python-version }}

  test-backward-compatibility:
    name: Test backward compatibility
    runs-on: ubuntu-latest
    needs: test

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install Java
      uses: actions/setup-java@v3
      with:
        distribution: 'temurin'
        java-version: '11'

    - name: Install all packages
      run: |
        python -m pip install --upgrade pip
        cd spark-session-utilities && pip install -e . && cd ..
        cd databricks-uc-utilities && pip install -e . && cd ..
        cd databricks-shared-utilities && pip install -e ".[dev]" && cd ..

    - name: Run backward compatibility tests
      working-directory: databricks-shared-utilities
      run: |
        pytest tests/contract -v

  build:
    name: Build package
    runs-on: ubuntu-latest
    needs: [test, test-backward-compatibility]

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install build tools
      run: |
        python -m pip install --upgrade pip
        pip install build twine

    - name: Build package
      working-directory: databricks-shared-utilities
      run: |
        python -m build

    - name: Check package
      working-directory: databricks-shared-utilities
      run: |
        twine check dist/*

    - name: Upload build artifacts
      uses: actions/upload-artifact@v3
      with:
        name: databricks-shared-utilities-dist
        path: databricks-shared-utilities/dist/
