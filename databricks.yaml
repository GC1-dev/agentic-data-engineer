# Databricks Asset Bundle configuration for databricks-meta-search-silver-domain
# See https://docs.databricks.com/dev-tools/bundles/index.html for documentation.

bundle:
  name: agentic-data-engineer

artifacts:
  # Standard distribution (lightweight wheel, requires dependency resolution)
  standard-wheel:
    type: whl
    path: .
    build: |
        # Get version from variable or git tags or pyproject.toml
        if [ -n "${var.package_version}" ] && [ "${var.package_version}" != "1.0.0" ]; then
          export PACKAGE_VERSION="${var.package_version}"
          echo "Using version from bundle var: ${var.package_version}"
        else
          # Fetch git tags to get correct version
          git fetch --tags 2>/dev/null || true
          VERSION=$(git describe --tags --abbrev=0 2>/dev/null | sed 's/^v//' || echo "")
          if [ -n "$VERSION" ]; then
            export PACKAGE_VERSION="$VERSION"
            echo "Using version from git tags: $VERSION"
          else
            echo "Using version from pyproject.toml"
          fi
        fi && \
        # Build fat distribution first (it cleans directories) - call script directly to avoid make venv check
        bash scripts/build-fat-dist.sh && \
        # Then build standard wheel (won't be cleaned)
        poetry build -f wheel && \
        poetry run pip list --format=freeze > requirements.txt && \
        mkdir -p ./dependency_wheels && \
        pip wheel -r requirements.txt -w ./dependency_wheels && \
        find dist dependency_wheels -type f -name "*.whl" | sed "s|^|${workspace.file_path}/|" > requirements-dabs.txt

variables:
  package_version:
    description: The version number for the package build
    default: "1.0.0"
  env:
    description: This is the environment variable for tasks
    default: "dev"
  squad:
    description: This is the squad name
    default: zurg
  project:
    description: This is the AWS project name.
    default: data-exemplar-slv
  service_principal_application_id:
    description: The application ID of the service principal used to deploy the DAB. Passed in by the spark reusable workflow.
    default: bcfc93d0-4c4a-460c-851f-4eb6e5fcec01


  workflow_trigger_status:
    description: This is the status of the workflow trigger
    default: "PAUSED"
  schedule_pause_status:
    description: This is the status of the workflow schedule
    default: "PAUSED"
  github_branch_name:
    description: The github branch name used to deploy the bundle
    default: "dev"

# Sync configuration - only sync src, notebooks, and pipelines
sync:
  include:
    - "src/"
    - "config/"
    - "libs/"
    - "pipelines/"
    - "notebooks/"
    - "dashboards/"
    - "data_contracts/"
    - "data_monitoring/"
    - "data_analysis/"
    - "data_validation/"    
    - "scripts/"
    - "docs/"
    - "reports/"
    - "drivers/"
    - "examples/"
    - "schema/"
    - "Makefile"
    - ".catalog.yml"
    - "dist/"
    - "fatdist/"

  exclude:
    - "*.cfg"
    - "*.ipynb"
    - "*.pre-commit-config.yaml"
    - "tests/"
    - "*venv"
    - "*.md"
    - "*.toml"
    - "*.gitignore"
    - ".github"
    - "*.databricksignore"

targets:
  # Development target
  dev:
    # Note: No mode set - allows custom workspace paths
    # mode: development enforces paths under /Workspace/Users/<service-principal-id>/
    default: true
    # mode: production

    workspace:
      root_path: "/Workspace/Users/bcfc93d0-4c4a-460c-851f-4eb6e5fcec01/.bundle/${bundle.name}"

    permissions:
      - level: CAN_MANAGE
        service_principal_name: bcfc93d0-4c4a-460c-851f-4eb6e5fcec01


      - level: CAN_MANAGE
        group_name: "Zurg Squad"

    variables:
      env: dev
      workflow_trigger_status: "PAUSED"
      schedule_pause_status: "PAUSED"

    presets:
      tags:
        squad: "${var.squad}"
        project: "${var.project}"
        target: "${bundle.target}"

    run_as:
      service_principal_name: bcfc93d0-4c4a-460c-851f-4eb6e5fcec01